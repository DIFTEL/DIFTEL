# J.A.R.V.I.S

Proyecto de asistente virtual dentro de una Raspeberry Pi con headset  (con entradas separadas de audÃ­fonos + micrÃ³fono) conectado a travÃ©s de adaptador USB to jack 3.5. Desarrollo incremental

Pasos para realizar el proyecto en tu mÃ¡quina desde cero

## 1. ğŸ“¦ Instalar dependencias necesarias

```bash
sudo apt update
sudo apt install python3-full python3-venv portaudio19-dev python3-pyaudio
sudo apt-get install flac
```

Esto instala:

* Paquetes de desarrollo necesarios (portaudio19-dev, pyaudio)
* MÃ³dulo venv para crear entornos virtuales
* El mÃ³dulo speech_recognition utiliza Google Speech Recognition API, que espera archivos de audio en formato FLAC. Este mÃ³dulo intenta usar la herramienta flac instalada en tu sistema para hacer la conversiÃ³n desde el formato WAV que produce PyAudio u otras fuentes.

## 2. ğŸ§ª Crear entorno virtual

```bash
mkdir ~/jarvis_proyecto
cd ~/jarvis_proyecto
python3 -m venv venv
```

## 3. âœ… Activar el entorno virtual

```bash
source venv/bin/activate
```

Cuando estÃ© activado, deberÃ­as ver algo asÃ­ en la terminal:
```bash
(venv) pi@raspberrypi:~/jarvis_proyecto $
```

### ğŸ§¼ Salir del entorno virtual
Cuando termines de trabajar:

```bash
deactivate
```

## 4. ğŸ“¥ Instalar SpeechRecognition y otras librerÃ­as dentro del entorno

Con el entorno activado:

```bash
pip install SpeechRecognition
pip install PyAudio
```

âš ï¸ Si PyAudio da error, puedes instalarlo con apt en lugar de pip:

```bash
Editar
sudo apt install python3-pyaudio
```

## 5. Buscar el indice de tu dispositivo de audio

Utilizando la librerÃ­a `speech_recognition`, puede encontrar la salida de audio deseada con el siguiente script:

```python
import speech_recognition as sr

r = sr.Recognizer()

# Listar micrÃ³fonos
for i, mic_name in enumerate(sr.Microphone.list_microphone_names()):
    print(f"{i}: {mic_name}")
```

o tambiÃ©n,

```python
import speech_recognition as sr

for i, name in enumerate(sr.Microphone.list_microphone_names()):
    print(f"{i}: {name}")
```

En mi caso obtuve la siguiente salida al final de una larga lista de advertencias tÃ­picas cuando ALSA intenta acceder a configuraciones de audio que no existen o no estÃ¡n definidas en el sistem (como surround51, hdmi, iec958, etc).

```bash
0: bcm2835 Headphones: - (hw:0,0)
1: USB PnP Sound Device: Audio (hw:3,0)
2: sysdefault
3: lavrate
4: samplerate
5: speexrate
6: pulse
7: speex
8: upmix
9: vdownmix
10: dmix
11: default
```

Por lo que el indice del dispositivo de salida es 1, informaciÃ³n que utilizaremos para los scripts python.

## 6. ğŸ§ª Probar script primera version

Funciona por activaciÃ³n por palabra clave y responde a una sola pregunta.

Ejecuta con

```bash
python reconocimiento_basico.py
```

## 7. ğŸ§ª Probar script segunda version

Modo continuo: Jarvis siempre escuchando y respondiendo mÃºltiples preguntas

* Jarvis se activa al decir "tony".
* Luego entra en modo escucha continua: responde preguntas una tras otra sin tener que reiniciar el script.
* Puedes salir con una palabra como "salir" o "apagar jarvis"

```bash
python reconocimiento_continuo.py
```

## 8. ğŸ§ª Probar script tercera version

Afinar el reconocimiento continuo implica lograr que Jarvis:

âœ… Responda fluida y continuamente mientras espera preguntas.

âœ… No necesite reiniciarse manualmente para cada pregunta.

âœ… Evite errores comunes como quedarse â€œcolgadoâ€ o interpretar ruidos como comandos.

âœ… Sea tolerante al silencio y maneje errores de escucha.

ğŸ”§ Mejoras recomendadas al reconocimiento continuo
AquÃ­ tienes una versiÃ³n refinada del cÃ³digo con:

* Tiempo mÃ¡ximo de espera (timeout) y duraciÃ³n mÃ¡xima de escucha (phrase_time_limit).
* Manejo mÃ¡s robusto de errores.
* DetecciÃ³n mÃ¡s clara de â€œesperandoâ€, â€œpreguntandoâ€, â€œsaliendoâ€.

âœ… CaracterÃ­sticas tÃ©cnicas incluidas:
adjust_for_ambient_noise: mejora el reconocimiento en ambientes ruidosos.

* timeout: evita que se bloquee esperando audio indefinidamente.
* phrase_time_limit: limita duraciÃ³n de lo que se dice.
* try-except bien distribuido: mayor robustez.

```bash
python reconocimiento_robusto.py
```

## ğŸ”œ Posibles prÃ³ximos pasos:
* AÃ±adir feedback de voz con pyttsx3.
* Usar un bucle infinito que detecte otras Ã³rdenes: abrir apps, consultar clima, reproducir mÃºsica, etc.
* Entrenar modelos offline con vosk o whisper para no depender de internet.
* SÃ­ntesis de voz (text-to-speech) con pyttsx3 o gTTS.
* Reconocimiento de mÃºltiples palabras clave (â€œtonyâ€, â€œjarvisâ€, etc).
* IntegraciÃ³n con hardware (LEDs, sensores en Raspberry Pi, etc.).